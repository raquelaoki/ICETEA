{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "This notebook runs causal inference methods on semi-synthetic datasets generated using the ICETEA framework. \n",
        "\n",
        "In this example, we use the AIPW estimator with three base-models: \n",
        "- inceptionV3\n",
        "- resnet50 \n",
        "- linear regression\n",
        "\n",
        "The functions assume the dataset is available in a folder in TFRecord format. If running on Google Colab, we recommend saving this dataset on Google Drive. We also recommend the adoption of GPUs for better performance. "
      ],
      "metadata": {
        "id": "28y8gnMXjTqO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VR0rofWuNUsF"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!mkdir estimators \n",
        "!git clone --branch clean_up https://github.com/raquelaoki/icetea\n",
        "!mv  -v /content/icetea/* /content/"
      ],
      "metadata": {
        "id": "svN5-Ao1JL9S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "034663ad-a1e5-45c5-a888-c8fb550678d7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'icetea'...\n",
            "remote: Enumerating objects: 308, done.\u001b[K\n",
            "remote: Counting objects: 100% (308/308), done.\u001b[K\n",
            "remote: Compressing objects: 100% (208/208), done.\u001b[K\n",
            "remote: Total 308 (delta 152), reused 235 (delta 82), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (308/308), 410.38 KiB | 6.22 MiB/s, done.\n",
            "Resolving deltas: 100% (152/152), done.\n",
            "renamed '/content/icetea/config_yaml' -> '/content/config_yaml'\n",
            "renamed '/content/icetea/estimators' -> '/content/estimators'\n",
            "renamed '/content/icetea/helper_data.py' -> '/content/helper_data.py'\n",
            "renamed '/content/icetea/helper_parameters.py' -> '/content/helper_parameters.py'\n",
            "renamed '/content/icetea/icetea_data_simulation.py' -> '/content/icetea_data_simulation.py'\n",
            "renamed '/content/icetea/icetea_feature_extraction.py' -> '/content/icetea_feature_extraction.py'\n",
            "renamed '/content/icetea/main.py' -> '/content/main.py'\n",
            "renamed '/content/icetea/notebooks' -> '/content/notebooks'\n",
            "renamed '/content/icetea/plots.py' -> '/content/plots.py'\n",
            "renamed '/content/icetea/README.md' -> '/content/README.md'\n",
            "renamed '/content/icetea/requirements.txt' -> '/content/requirements.txt'\n",
            "renamed '/content/icetea/script_gpu.sh' -> '/content/script_gpu.sh'\n",
            "renamed '/content/icetea/script_vm.sh' -> '/content/script_vm.sh'\n",
            "renamed '/content/icetea/utils.py' -> '/content/utils.py'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rw8DyEK6Qfin",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06a33304-d00e-4e3a-fdf2-80fe6c145a22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "import logging\n",
        "import tensorflow as tf\n",
        "from tensorflow.io import gfile\n",
        "import matplotlib.pyplot as plt\n",
        "import yaml\n",
        "\n",
        "#Local Imports \n",
        "import helper_data as hd\n",
        "import icetea_feature_extraction as fe\n",
        "import icetea_data_simulation as ds \n",
        "import utils \n",
        "import plots\n",
        "import helper_parameters as hp\n",
        "\n",
        "debuging = False\n",
        "use_tpu = False\n",
        "strategy = None\n",
        "\n",
        "#logging.basicConfig(level=logging.DEBUG)\n",
        "\n",
        "path_config = '/content/config_yaml/'\n",
        "\n",
        "if debuging: \n",
        "  config_paths ={\n",
        "      'path_root':'/content/drive/MyDrive/ColabNotebooks/data',\n",
        "      'path_images_png':'icetea_png/sample/' ,\n",
        "      'path_tfrecords':'testing/' ,\n",
        "      'path_tfrecords_new':'new_data_small/',\n",
        "      'path_features':'testing/' ,\n",
        "      'path_results':'testing/' ,\n",
        "      'path_meta':'trainLabels.csv'\n",
        "  }\n",
        "else:\n",
        "    with open(os.path.join(path_config, 'paths.yaml')) as f:\n",
        "      config_paths = yaml.safe_load(f)\n",
        "    config_paths = config_paths['parameters']\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "for key in config_paths: \n",
        "  if key!= 'path_root': \n",
        "    path = os.path.join(config_paths['path_root'], config_paths[key])\n",
        "  else: \n",
        "    path = config_paths['path_root']\n",
        "  \n",
        "  if key != 'path_meta':\n",
        "    assert os.path.isdir(path), config_paths[key]+ ': Folder does not exist!'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CntbkFOACiv",
        "outputId": "ab222101-decf-46f1-eea6-ed7f341536cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jun  3 22:52:21 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OeMjt6kNNGw"
      },
      "source": [
        "# Causal Inference \n",
        "\n",
        "We illustrate how to use the dataset with an AIPW and three different base-models. \n",
        "\n",
        "First, we load a list with all available synthetic datasets. These datasets should already be part of the TFRecord files. (The Data Simulation phase takes care of it.)\n",
        "\n",
        "Each row on list_of_datasets is the seed of a semi-synthetic dataset generated with ICETEA. `sim_id` is a unique identifier of the datasets, defined by their knobs, setting id, and repetition index. Check icetea_feature_extraction_data_simulation.ipynb for a complete description on it. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZbl3l5zHw_6",
        "outputId": "ea78dacc-5643-42ce-df0d-4697f2e32ab4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0  gamma repetition knob setting_id                  sim_id  \\\n",
            "0           0    0.5         b0   ks        ks0  sim_ks0_b0_0.1_0.5_0.5   \n",
            "1           1    1.0         b0   kh        kh2     sim_kh2_b0_10_0.5_1   \n",
            "2           2    0.5         b0   kh        kh1   sim_kh1_b0_10_0.5_0.5   \n",
            "3           3    0.5         b0   ko        ko0     sim_ko0_b0_10_0_0.5   \n",
            "4           4    0.5         b0   ko        ko1   sim_ko1_b0_10_0.5_0.5   \n",
            "\n",
            "        tau  setting  alpha  beta running  \n",
            "0 -1.270433        0    0.1   0.5     yes  \n",
            "1  1.000000        2   10.0   0.5    done  \n",
            "2  1.000000        1   10.0   0.5    done  \n",
            "3  1.000000        0   10.0   0.0    done  \n",
            "4  1.000000        1   10.0   0.5    done  \n",
            "Total:  270\n"
          ]
        }
      ],
      "source": [
        "list_of_datasets = pd.read_csv(os.path.join(config_paths['path_root'], \n",
        "                                            config_paths['path_features'],\n",
        "                                            'true_tau_sorted.csv'))\n",
        "\n",
        "print(list_of_datasets.head())\n",
        "print('Total: ',list_of_datasets.shape[0])\n",
        "\n",
        "#Below we pick two seeds, indexes 0 and 1, to run the estimators:\n",
        "running_indexes=[0,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading config files:"
      ],
      "metadata": {
        "id": "85Ii8EnEpmtM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(os.path.join(path_config, 'causal_inference_setup.yaml')) as f:\n",
        "    config_ci = yaml.safe_load(f)\n",
        "config_ci = config_ci['parameters']\n",
        "\n",
        "param_data = {}\n",
        "param_data = utils.adding_paths_to_config(param_data, config_paths)\n",
        "param_data['image_size'] = config_ci['image_size']\n",
        "param_data['batch_size'] = config_ci['batch_size']\n",
        "param_data['name'] = config_ci['name_data']\n",
        "param_data['prefix_train'] = config_ci['prefix_train']\n",
        "param_data['path_tfrecords_new'] = os.path.join(param_data['path_root'],param_data['path_tfrecords_new'])\n",
        "param_data['output_name'] = config_ci['output_name'] \n",
        "\n",
        "param_method = {}\n",
        "#param_method = utils.adding_paths_to_config(param_method, config_paths)\n",
        "param_method['name_estimator'] = config_ci['name_estimator']\n",
        "param_method['name_metric'] = config_ci['name_metric']\n",
        "param_method['name_base_model'] = config_ci['name_base_model']\n",
        "param_method['learn_prop_score'] = config_ci['learn_prop_score']\n",
        "param_method['name_prop_score'] = config_ci['name_prop_score']\n",
        "param_method['epochs'] = config_ci['epochs']\n",
        "param_method['steps'] = config_ci['steps']\n",
        "model_repetitions = config_ci.get('repetitions',1)\n",
        "\n",
        "if debuging:\n",
        "  param_method['epochs']= [1]\n",
        "  param_method['steps'] = [1]\n",
        "  param_data['batch_size']=4\n",
        "\n",
        "print(param_method)\n",
        "config_methods = hp.create_configs(param_method)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIuXzrLDmCFB",
        "outputId": "0d968b45-c584-45df-f791-34ff21684b20"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name_estimator': ['aipw'], 'name_metric': ['mse'], 'name_base_model': ['image_regression', 'resnet50', 'inceptionv3'], 'learn_prop_score': [False], 'name_prop_score': [''], 'epochs': [5], 'steps': [5]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the simulations for the selected indexes. \n",
        "\n",
        "Approximated time per index: ~1h 30m (depends on GPU)."
      ],
      "metadata": {
        "id": "PJ1OB4WHwSIT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJcfjy6BN06w"
      },
      "outputs": [],
      "source": [
        "for i, sim_id in enumerate(list_of_datasets['sim_id']):\n",
        "  if i in running_indexes: \n",
        "    print('running ', i)\n",
        "    #  Loads dataset with appropried sim_id.\n",
        "    #  Creates a temporary DataFrame to keep the repetitions results under this dataset;\n",
        "    #  Meaning: data is loaded once, and we have several models (defined in parameters.config_methods)\n",
        "    #  using this dataset. \n",
        "    results_one_dataset = pd.DataFrame()\n",
        "    for _config in config_methods:\n",
        "        _config['image_size'] = config_ci['image_size'][0]\n",
        "        results_one_config = utils.repeat_experiment(param_data=param_data,\n",
        "                                                      param_method=_config,\n",
        "                                                      seed_data=sim_id,\n",
        "                                                      seed_method=i,\n",
        "                                                      use_tpu=use_tpu,\n",
        "                                                      strategy=strategy)\n",
        "        results_one_config['sim_id'] = sim_id\n",
        "        results_one_config = pd.merge(results_one_config, list_of_datasets, how='left')\n",
        "        results_one_dataset = pd.concat([results_one_dataset, results_one_config])\n",
        "        # Intermediate save.\n",
        "        utils.save_results(using_gc=False, params=param_data, results=results_one_dataset, i=i)\n",
        "    # Final save.\n",
        "    utils.save_results(using_gc=False, params=param_data, results=results_one_dataset, i=i)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_one_dataset"
      ],
      "metadata": {
        "id": "Q6X8MrcRu8hn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "name": "icetea_causal_inference.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}